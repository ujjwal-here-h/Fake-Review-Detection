{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "import pandas as pd\n",
    "import nltk\n",
    "#import spacy\n",
    "import re\n",
    "import string,unicodedata\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "#from py_lex import EmoLex\n",
    "from textblob import TextBlob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from spellchecker import SpellChecker\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn import preprocessing\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>prod_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>label</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>923</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "      <td>08-12-2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>924</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "      <td>16-05-2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>925</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>-1</td>\n",
       "      <td>01-07-2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>926</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>-1</td>\n",
       "      <td>28-07-2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>927</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>-1</td>\n",
       "      <td>01-11-2010</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  prod_id  rating  label        date\n",
       "0      923        0       3     -1  08-12-2014\n",
       "1      924        0       3     -1  16-05-2013\n",
       "2      925        0       4     -1  01-07-2013\n",
       "3      926        0       4     -1  28-07-2011\n",
       "4      927        0       4     -1  01-11-2010"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1= pd.read_csv(\"metadata_nyc.csv\")\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>prod_id</th>\n",
       "      <th>date</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>923</td>\n",
       "      <td>0</td>\n",
       "      <td>08-12-2014</td>\n",
       "      <td>The food at snack is a selection of popular Gr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>924</td>\n",
       "      <td>0</td>\n",
       "      <td>16-05-2013</td>\n",
       "      <td>This little place in Soho is wonderful. I had ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>925</td>\n",
       "      <td>0</td>\n",
       "      <td>01-07-2013</td>\n",
       "      <td>ordered lunch for 15 from Snack last Friday.  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>926</td>\n",
       "      <td>0</td>\n",
       "      <td>28-07-2011</td>\n",
       "      <td>This is a beautiful quaint little restaurant o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>927</td>\n",
       "      <td>0</td>\n",
       "      <td>01-11-2010</td>\n",
       "      <td>Snack is great place for a  casual sit down lu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  prod_id        date  \\\n",
       "0      923        0  08-12-2014   \n",
       "1      924        0  16-05-2013   \n",
       "2      925        0  01-07-2013   \n",
       "3      926        0  28-07-2011   \n",
       "4      927        0  01-11-2010   \n",
       "\n",
       "                                              review  \n",
       "0  The food at snack is a selection of popular Gr...  \n",
       "1  This little place in Soho is wonderful. I had ...  \n",
       "2  ordered lunch for 15 from Snack last Friday.  ...  \n",
       "3  This is a beautiful quaint little restaurant o...  \n",
       "4  Snack is great place for a  casual sit down lu...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2= pd.read_csv(\"reviewContentNYC.csv\")\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1[\"review\"]=df2[\"review\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>user_id</th>\n",
       "      <th>prod_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>review</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>08-12-2014</td>\n",
       "      <td>923</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>The food at snack is a selection of popular Gr...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>16-05-2013</td>\n",
       "      <td>924</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>This little place in Soho is wonderful. I had ...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>01-07-2013</td>\n",
       "      <td>925</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>ordered lunch for 15 from Snack last Friday.  ...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>28-07-2011</td>\n",
       "      <td>926</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>This is a beautiful quaint little restaurant o...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>01-11-2010</td>\n",
       "      <td>927</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>Snack is great place for a  casual sit down lu...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date  user_id  prod_id  rating  \\\n",
       "0  08-12-2014      923        0       3   \n",
       "1  16-05-2013      924        0       3   \n",
       "2  01-07-2013      925        0       4   \n",
       "3  28-07-2011      926        0       4   \n",
       "4  01-11-2010      927        0       4   \n",
       "\n",
       "                                              review  label  \n",
       "0  The food at snack is a selection of popular Gr...     -1  \n",
       "1  This little place in Soho is wonderful. I had ...     -1  \n",
       "2  ordered lunch for 15 from Snack last Friday.  ...     -1  \n",
       "3  This is a beautiful quaint little restaurant o...     -1  \n",
       "4  Snack is great place for a  casual sit down lu...     -1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columntitles=[\"date\",\"user_id\",\"prod_id\",\"rating\",\"review\",\"label\"]\n",
    "df1=df1.reindex(columns=columntitles)\n",
    "df= df1\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(359052, 6)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 1    322167\n",
       "-1     36885\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"label\"].value_counts()              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    322167\n",
       "0     36885\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"label\"]=df[\"label\"].replace(-1,0)                #1 authentic     #0 fake\n",
    "df[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(73770, 5)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1    36885\n",
       "0    36885\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ros = RandomUnderSampler(random_state=777)\n",
    "dfx, dfy = ros.fit_sample(df.iloc[:,0:5], df.label)\n",
    "print(dfx.shape)\n",
    "df = pd.concat([dfx, dfy], axis = 1)\n",
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(73770, 6)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape                                                                                                           #upto here this file is saved as \"mappeddata_NYC.csv\" for future reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1 Average User rating\n",
    "temp= df.groupby(['user_id'])['rating'].agg(np.mean).reset_index()\n",
    "temp.rename(columns={'rating':'avg_Urating'}, inplace=True)\n",
    "df = pd.merge(df, temp, how='outer', on=['user_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2 Average Product rating\n",
    "temp= df.groupby(['prod_id'])['rating'].agg(np.mean).reset_index()\n",
    "temp.rename(columns={'rating':'avg_Prating'}, inplace=True)\n",
    "df = pd.merge(df, temp, how='outer', on=['prod_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3 No. of reviews by a user\n",
    "temp = df['user_id'].value_counts().rename_axis('user_id').to_frame('UCcounts')\n",
    "df = pd.merge(df, temp, how='outer', on=['user_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4 No. of reviews on a product\n",
    "temp = df['prod_id'].value_counts().rename_axis('prod_id').to_frame('PCcounts')\n",
    "df = pd.merge(df, temp, how='outer', on=['prod_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5 Number of words(review length)\n",
    "df['#ofwords'] = df['review'].str.count(' ') + 1\n",
    "#6 Avg word count in user's review\n",
    "temp = df.groupby(['user_id'])['#ofwords'].agg(np.mean).reset_index()\n",
    "temp.rename(columns={'#ofwords':'Uavg#word'}, inplace=True)\n",
    "df = pd.merge(df, temp, how='outer', on=['user_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#7 Rating deviation                                      #Mine 1\n",
    "df[\"ratdev\"]=(df[\"avg_Prating\"]-df1[\"rating\"]).abs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['postags'] = nltk.tag.pos_tag_sents(df['review'].apply(nltk.word_tokenize).tolist())                                    #took 18 min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NounCounter(x):\n",
    "    nouns = []\n",
    "    for (word, pos) in x:\n",
    "        if pos.startswith(\"NN\"):\n",
    "            nouns.append(word)\n",
    "    return nouns\n",
    "\n",
    "df[\"nouns\"] = df[\"postags\"].apply(NounCounter)\n",
    "df[\"noun_count\"] = df[\"nouns\"].str.len()\n",
    "\n",
    "\n",
    "def VerbCounter(x):\n",
    "    verbs = []\n",
    "    for (word, pos) in x:\n",
    "        if pos.startswith(\"VB\"):\n",
    "            verbs.append(word)\n",
    "    return verbs\n",
    "\n",
    "df[\"verbs\"] = df[\"postags\"].apply(VerbCounter)\n",
    "df[\"verb_count\"] = df[\"verbs\"].str.len()\n",
    "\n",
    "\n",
    "def AdverbCounter(x):\n",
    "    adverbs = []\n",
    "    for (word, pos) in x:\n",
    "        if pos.startswith(\"RB\"):\n",
    "            adverbs.append(word)\n",
    "    return adverbs\n",
    "\n",
    "df[\"adverbs\"] = df[\"postags\"].apply(AdverbCounter)\n",
    "df[\"adverb_count\"] = df[\"adverbs\"].str.len()\n",
    "\n",
    "\n",
    "def AdjCounter(x):\n",
    "    adjs = []\n",
    "    for (word, pos) in x:\n",
    "        if pos.startswith(\"JJ\"):\n",
    "            adjs.append(word)\n",
    "    return adjs\n",
    "\n",
    "df[\"adjectives\"] = df[\"postags\"].apply(AdjCounter)\n",
    "df[\"adj_count\"] = df[\"adjectives\"].str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    " #8 noun%                                                        #Mine 2\n",
    "df[\"noun%\"]= (df[\"noun_count\"]/df[\"#ofwords\"])*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#9 imaginative to informative ratio                              #Mine 3\n",
    "df[\"imag_to_info\"]= (df[\"adverb_count\"]+df[\"verb_count\"])/(df[\"noun_count\"]+df[\"adj_count\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#10 self reference diversity                                     #Mine 4\n",
    "def PronounCounter(x):\n",
    "    pronouns = []\n",
    "    for (word, pos) in x:\n",
    "        if pos.startswith(\"PRP\"):\n",
    "            pronouns.append(word)\n",
    "    return pronouns\n",
    "\n",
    "df[\"pronouns\"] = df[\"postags\"].apply(PronounCounter)\n",
    "df[\"pronoun_count\"] = df[\"pronouns\"].str.len()\n",
    "\n",
    "\n",
    "def PossPronounCounter(x):\n",
    "    posspronouns = []\n",
    "    for (word, pos) in x:\n",
    "        if pos.startswith(\"PRP$\"):\n",
    "            posspronouns.append(word)\n",
    "    return posspronouns\n",
    "\n",
    "df[\"posspronouns\"] = df[\"postags\"].apply(PossPronounCounter)\n",
    "df[\"posspronoun_count\"] = df[\"posspronouns\"].str.len()\n",
    "\n",
    "df[\"perprocount\"]= df[\"pronoun_count\"]-df[\"posspronoun_count\"]                 \n",
    "df[\"selfreference_div\"]= df[\"perprocount\"]/df[\"pronoun_count\"]                                                         #remember to change empty valus to 0 in this column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#11 capital counts                                               #Mine 5\n",
    "def tokens(text):\n",
    "    return  str(text).split() \n",
    "df[\"tokens\"]= df[\"review\"].apply(tokens)\n",
    "\n",
    "def countcapital(wordarray):\n",
    "    count=0\n",
    "    for word in wordarray:\n",
    "        if(word.isupper()):\n",
    "            count=count+1\n",
    "    return count    \n",
    "\n",
    "df[\"capitals\"]= df[\"tokens\"].apply(countcapital)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>user_id</th>\n",
       "      <th>prod_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>review</th>\n",
       "      <th>label</th>\n",
       "      <th>avg_Urating</th>\n",
       "      <th>avg_Prating</th>\n",
       "      <th>UCcounts</th>\n",
       "      <th>PCcounts</th>\n",
       "      <th>...</th>\n",
       "      <th>noun%</th>\n",
       "      <th>imag_to_info</th>\n",
       "      <th>pronouns</th>\n",
       "      <th>pronoun_count</th>\n",
       "      <th>posspronouns</th>\n",
       "      <th>posspronoun_count</th>\n",
       "      <th>perprocount</th>\n",
       "      <th>selfreference_div</th>\n",
       "      <th>tokens</th>\n",
       "      <th>capitals</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>08-12-2014</td>\n",
       "      <td>923</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>The food at snack is a selection of popular Gr...</td>\n",
       "      <td>0</td>\n",
       "      <td>4.435897</td>\n",
       "      <td>4.071429</td>\n",
       "      <td>39</td>\n",
       "      <td>42</td>\n",
       "      <td>...</td>\n",
       "      <td>22.500000</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>[We, it]</td>\n",
       "      <td>2</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>[The, food, at, snack, is, a, selection, of, p...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>14-01-2014</td>\n",
       "      <td>923</td>\n",
       "      <td>19</td>\n",
       "      <td>5</td>\n",
       "      <td>The restaurant is on the ground floor of a typ...</td>\n",
       "      <td>0</td>\n",
       "      <td>4.435897</td>\n",
       "      <td>4.261905</td>\n",
       "      <td>39</td>\n",
       "      <td>84</td>\n",
       "      <td>...</td>\n",
       "      <td>27.083333</td>\n",
       "      <td>0.435897</td>\n",
       "      <td>[You, it, you, it, I, they, I]</td>\n",
       "      <td>7</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1.00</td>\n",
       "      <td>[The, restaurant, is, on, the, ground, floor, ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>30-05-2014</td>\n",
       "      <td>923</td>\n",
       "      <td>40</td>\n",
       "      <td>4</td>\n",
       "      <td>Really nice mousaka and lovely décor inside. A...</td>\n",
       "      <td>0</td>\n",
       "      <td>4.435897</td>\n",
       "      <td>4.326829</td>\n",
       "      <td>39</td>\n",
       "      <td>205</td>\n",
       "      <td>...</td>\n",
       "      <td>23.255814</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>[I, my, It, I]</td>\n",
       "      <td>4</td>\n",
       "      <td>[my]</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.75</td>\n",
       "      <td>[Really, nice, mousaka, and, lovely, décor, in...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>13-11-2014</td>\n",
       "      <td>923</td>\n",
       "      <td>63</td>\n",
       "      <td>4</td>\n",
       "      <td>I really enjoyed brunch at Jane. The ambiance ...</td>\n",
       "      <td>0</td>\n",
       "      <td>4.435897</td>\n",
       "      <td>3.894737</td>\n",
       "      <td>39</td>\n",
       "      <td>323</td>\n",
       "      <td>...</td>\n",
       "      <td>20.588235</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[I, you, it]</td>\n",
       "      <td>3</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.00</td>\n",
       "      <td>[I, really, enjoyed, brunch, at, Jane., The, a...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>30-03-2014</td>\n",
       "      <td>923</td>\n",
       "      <td>79</td>\n",
       "      <td>3</td>\n",
       "      <td>We ate at the Blue Ribbon with colleagues. The...</td>\n",
       "      <td>0</td>\n",
       "      <td>4.435897</td>\n",
       "      <td>4.352941</td>\n",
       "      <td>39</td>\n",
       "      <td>170</td>\n",
       "      <td>...</td>\n",
       "      <td>22.448980</td>\n",
       "      <td>0.722222</td>\n",
       "      <td>[We, it]</td>\n",
       "      <td>2</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>[We, ate, at, the, Blue, Ribbon, with, colleag...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         date  user_id  prod_id  rating  \\\n",
       "0  08-12-2014      923        0       3   \n",
       "1  14-01-2014      923       19       5   \n",
       "2  30-05-2014      923       40       4   \n",
       "3  13-11-2014      923       63       4   \n",
       "4  30-03-2014      923       79       3   \n",
       "\n",
       "                                              review  label  avg_Urating  \\\n",
       "0  The food at snack is a selection of popular Gr...      0     4.435897   \n",
       "1  The restaurant is on the ground floor of a typ...      0     4.435897   \n",
       "2  Really nice mousaka and lovely décor inside. A...      0     4.435897   \n",
       "3  I really enjoyed brunch at Jane. The ambiance ...      0     4.435897   \n",
       "4  We ate at the Blue Ribbon with colleagues. The...      0     4.435897   \n",
       "\n",
       "   avg_Prating  UCcounts  PCcounts  ...      noun%  imag_to_info  \\\n",
       "0     4.071429        39        42  ...  22.500000      0.687500   \n",
       "1     4.261905        39        84  ...  27.083333      0.435897   \n",
       "2     4.326829        39       205  ...  23.255814      0.666667   \n",
       "3     3.894737        39       323  ...  20.588235      1.000000   \n",
       "4     4.352941        39       170  ...  22.448980      0.722222   \n",
       "\n",
       "                         pronouns pronoun_count posspronouns  \\\n",
       "0                        [We, it]             2           []   \n",
       "1  [You, it, you, it, I, they, I]             7           []   \n",
       "2                  [I, my, It, I]             4         [my]   \n",
       "3                    [I, you, it]             3           []   \n",
       "4                        [We, it]             2           []   \n",
       "\n",
       "   posspronoun_count perprocount  selfreference_div  \\\n",
       "0                  0           2               1.00   \n",
       "1                  0           7               1.00   \n",
       "2                  1           3               0.75   \n",
       "3                  0           3               1.00   \n",
       "4                  0           2               1.00   \n",
       "\n",
       "                                              tokens  capitals  \n",
       "0  [The, food, at, snack, is, a, selection, of, p...         0  \n",
       "1  [The, restaurant, is, on, the, ground, floor, ...         2  \n",
       "2  [Really, nice, mousaka, and, lovely, décor, in...         3  \n",
       "3  [I, really, enjoyed, brunch, at, Jane., The, a...         2  \n",
       "4  [We, ate, at, the, Blue, Ribbon, with, colleag...         0  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#12 assumption and future words count                            #Mine 6\n",
    "  \n",
    "from nltk.corpus import wordnet                                                                                        #took 2 mins  # means pos_tag takes time\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "wordnet_map = {\"N\":wordnet.NOUN, \"V\":wordnet.VERB, \"J\":wordnet.ADJ, \"R\":wordnet.ADV}\n",
    "def lemmatize_words(text):\n",
    "    pos_tagged_text = text\n",
    "    return \" \".join([lemmatizer.lemmatize(word, wordnet_map.get(pos[0], wordnet.NOUN)) for word, pos in pos_tagged_text])\n",
    "\n",
    "df[\"text_lemmatized\"] = df[\"postags\"].apply(lemmatize_words)\n",
    "\n",
    "df['lemmatizedtokens'] = df['text_lemmatized'].apply(nltk.word_tokenize).tolist()  \n",
    "\n",
    "assum_fut=[\"assume\",\"feel\",\"may\",\"think\",\"believe\",\"wonder\",\"will\",\"shall\",\"guess\"] \n",
    "\n",
    "def count(array):\n",
    "    count=0\n",
    "    for word in array:\n",
    "        if word in assum_fut:\n",
    "            count=count+1;\n",
    "    return count \n",
    "\n",
    "df[\"assum_fut_count\"]= df[\"lemmatizedtokens\"].apply(count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>user_id</th>\n",
       "      <th>prod_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>review</th>\n",
       "      <th>label</th>\n",
       "      <th>avg_Urating</th>\n",
       "      <th>avg_Prating</th>\n",
       "      <th>UCcounts</th>\n",
       "      <th>PCcounts</th>\n",
       "      <th>...</th>\n",
       "      <th>pronoun_count</th>\n",
       "      <th>posspronouns</th>\n",
       "      <th>posspronoun_count</th>\n",
       "      <th>perprocount</th>\n",
       "      <th>selfreference_div</th>\n",
       "      <th>tokens</th>\n",
       "      <th>capitals</th>\n",
       "      <th>text_lemmatized</th>\n",
       "      <th>lemmatizedtokens</th>\n",
       "      <th>assum_fut_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>08-12-2014</td>\n",
       "      <td>923</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>The food at snack is a selection of popular Gr...</td>\n",
       "      <td>0</td>\n",
       "      <td>4.435897</td>\n",
       "      <td>4.071429</td>\n",
       "      <td>39</td>\n",
       "      <td>42</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>[The, food, at, snack, is, a, selection, of, p...</td>\n",
       "      <td>0</td>\n",
       "      <td>The food at snack be a selection of popular Gr...</td>\n",
       "      <td>[The, food, at, snack, be, a, selection, of, p...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>14-01-2014</td>\n",
       "      <td>923</td>\n",
       "      <td>19</td>\n",
       "      <td>5</td>\n",
       "      <td>The restaurant is on the ground floor of a typ...</td>\n",
       "      <td>0</td>\n",
       "      <td>4.435897</td>\n",
       "      <td>4.261905</td>\n",
       "      <td>39</td>\n",
       "      <td>84</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1.00</td>\n",
       "      <td>[The, restaurant, is, on, the, ground, floor, ...</td>\n",
       "      <td>2</td>\n",
       "      <td>The restaurant be on the ground floor of a typ...</td>\n",
       "      <td>[The, restaurant, be, on, the, ground, floor, ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>30-05-2014</td>\n",
       "      <td>923</td>\n",
       "      <td>40</td>\n",
       "      <td>4</td>\n",
       "      <td>Really nice mousaka and lovely décor inside. A...</td>\n",
       "      <td>0</td>\n",
       "      <td>4.435897</td>\n",
       "      <td>4.326829</td>\n",
       "      <td>39</td>\n",
       "      <td>205</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>[my]</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.75</td>\n",
       "      <td>[Really, nice, mousaka, and, lovely, décor, in...</td>\n",
       "      <td>3</td>\n",
       "      <td>Really nice mousaka and lovely décor inside . ...</td>\n",
       "      <td>[Really, nice, mousaka, and, lovely, décor, in...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>13-11-2014</td>\n",
       "      <td>923</td>\n",
       "      <td>63</td>\n",
       "      <td>4</td>\n",
       "      <td>I really enjoyed brunch at Jane. The ambiance ...</td>\n",
       "      <td>0</td>\n",
       "      <td>4.435897</td>\n",
       "      <td>3.894737</td>\n",
       "      <td>39</td>\n",
       "      <td>323</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.00</td>\n",
       "      <td>[I, really, enjoyed, brunch, at, Jane., The, a...</td>\n",
       "      <td>2</td>\n",
       "      <td>I really enjoy brunch at Jane . The ambiance b...</td>\n",
       "      <td>[I, really, enjoy, brunch, at, Jane, ., The, a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>30-03-2014</td>\n",
       "      <td>923</td>\n",
       "      <td>79</td>\n",
       "      <td>3</td>\n",
       "      <td>We ate at the Blue Ribbon with colleagues. The...</td>\n",
       "      <td>0</td>\n",
       "      <td>4.435897</td>\n",
       "      <td>4.352941</td>\n",
       "      <td>39</td>\n",
       "      <td>170</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>[We, ate, at, the, Blue, Ribbon, with, colleag...</td>\n",
       "      <td>0</td>\n",
       "      <td>We eat at the Blue Ribbon with colleague . The...</td>\n",
       "      <td>[We, eat, at, the, Blue, Ribbon, with, colleag...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         date  user_id  prod_id  rating  \\\n",
       "0  08-12-2014      923        0       3   \n",
       "1  14-01-2014      923       19       5   \n",
       "2  30-05-2014      923       40       4   \n",
       "3  13-11-2014      923       63       4   \n",
       "4  30-03-2014      923       79       3   \n",
       "\n",
       "                                              review  label  avg_Urating  \\\n",
       "0  The food at snack is a selection of popular Gr...      0     4.435897   \n",
       "1  The restaurant is on the ground floor of a typ...      0     4.435897   \n",
       "2  Really nice mousaka and lovely décor inside. A...      0     4.435897   \n",
       "3  I really enjoyed brunch at Jane. The ambiance ...      0     4.435897   \n",
       "4  We ate at the Blue Ribbon with colleagues. The...      0     4.435897   \n",
       "\n",
       "   avg_Prating  UCcounts  PCcounts  ...  pronoun_count  posspronouns  \\\n",
       "0     4.071429        39        42  ...              2            []   \n",
       "1     4.261905        39        84  ...              7            []   \n",
       "2     4.326829        39       205  ...              4          [my]   \n",
       "3     3.894737        39       323  ...              3            []   \n",
       "4     4.352941        39       170  ...              2            []   \n",
       "\n",
       "   posspronoun_count perprocount selfreference_div  \\\n",
       "0                  0           2              1.00   \n",
       "1                  0           7              1.00   \n",
       "2                  1           3              0.75   \n",
       "3                  0           3              1.00   \n",
       "4                  0           2              1.00   \n",
       "\n",
       "                                              tokens capitals  \\\n",
       "0  [The, food, at, snack, is, a, selection, of, p...        0   \n",
       "1  [The, restaurant, is, on, the, ground, floor, ...        2   \n",
       "2  [Really, nice, mousaka, and, lovely, décor, in...        3   \n",
       "3  [I, really, enjoyed, brunch, at, Jane., The, a...        2   \n",
       "4  [We, ate, at, the, Blue, Ribbon, with, colleag...        0   \n",
       "\n",
       "                                     text_lemmatized  \\\n",
       "0  The food at snack be a selection of popular Gr...   \n",
       "1  The restaurant be on the ground floor of a typ...   \n",
       "2  Really nice mousaka and lovely décor inside . ...   \n",
       "3  I really enjoy brunch at Jane . The ambiance b...   \n",
       "4  We eat at the Blue Ribbon with colleague . The...   \n",
       "\n",
       "                                    lemmatizedtokens  assum_fut_count  \n",
       "0  [The, food, at, snack, be, a, selection, of, p...                0  \n",
       "1  [The, restaurant, be, on, the, ground, floor, ...                2  \n",
       "2  [Really, nice, mousaka, and, lovely, décor, in...                1  \n",
       "3  [I, really, enjoy, brunch, at, Jane, ., The, a...                0  \n",
       "4  [We, eat, at, the, Blue, Ribbon, with, colleag...                0  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('halfwaydone.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.read_csv('halfwaydone.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#13 #of reviews posted by a reviewer on a particular date               #Mine 7\n",
    "df[\"ones\"]= 1\n",
    "temp = df.groupby(['date','user_id'])['ones'].agg(np.count_nonzero).reset_index()\n",
    "temp.rename(columns={'ones':'U_rev_perday'}, inplace=True)\n",
    "df = pd.merge(df, temp, how='outer', on=['date','user_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#14 of reviews posted by a reviewer on a particular product -- multiple reviews             #Mine 8\n",
    "temp = df.groupby(['prod_id','user_id'])['ones'].agg(np.count_nonzero).reset_index()\n",
    "temp.rename(columns={'ones':'mul_rev'}, inplace=True)\n",
    "df = pd.merge(df, temp, how='outer', on=['prod_id','user_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#15 positive to negative ratio of a user                                   #Mine 9\n",
    "\n",
    "#4ormore\n",
    "temp= df.groupby(['user_id'])['rating'].agg(lambda val: (val >=4 ).sum()).reset_index()       \n",
    "temp.rename(columns={'rating':'4ormore'}, inplace=True)\n",
    "df = pd.merge(df, temp, how='outer', on=['user_id'])\n",
    "\n",
    "#2orless\n",
    "temp= df.groupby(['user_id'])['rating'].agg(lambda val: (val <=2 ).sum()).reset_index()        \n",
    "temp.rename(columns={'rating':'2orless'}, inplace=True)\n",
    "df = pd.merge(df, temp, how='outer', on=['user_id'])\n",
    "\n",
    "df[\"pos_to_neg_ratio\"]= df[\"4ormore\"]/df[\"2orless\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#16 Subjectivity \n",
    "df['review'] = df.review.astype(str)\n",
    "df['subjectivity'] = df['review'].apply(lambda tweet: TextBlob(tweet).sentiment.subjectivity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#17 Polarity\n",
    "df['review'] = df.review.astype(str)\n",
    "df['polarity'] = df['review'].apply(lambda tweet: TextBlob(tweet).sentiment.polarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#18 Rating\n",
    "#handling missing and inf values in self ref diversity and positive to neg ratio column\n",
    "df=df.replace([np.inf, -np.inf], np.nan)                  #all inf or -inf replaced by nan in whole dataset\n",
    "\n",
    "mean= df[\"selfreference_div\"].mean()\n",
    "df[\"selfreference_div\"].fillna(mean,inplace=True)\n",
    "\n",
    "mean=df[\"pos_to_neg_ratio\"].mean()\n",
    "df[\"pos_to_neg_ratio\"].fillna(mean,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'date', 'user_id', 'prod_id', 'rating', 'review', 'label',\n",
       "       'avg_Urating', 'avg_Prating', 'UCcounts', 'PCcounts', '#ofwords',\n",
       "       'Uavg#word', 'ratdev', 'postags', 'nouns', 'noun_count', 'verbs',\n",
       "       'verb_count', 'adverbs', 'adverb_count', 'adjectives', 'adj_count',\n",
       "       'noun%', 'imag_to_info', 'pronouns', 'pronoun_count', 'posspronouns',\n",
       "       'posspronoun_count', 'perprocount', 'selfreference_div', 'tokens',\n",
       "       'capitals', 'text_lemmatized', 'lemmatizedtokens', 'assum_fut_count',\n",
       "       'ones', 'U_rev_perday', 'mul_rev', '4ormore', '2orless',\n",
       "       'pos_to_neg_ratio', 'subjectivity', 'polarity'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Lowercasing'''\n",
    "df[\"reviewcopy\"]=df[\"review\"]\n",
    "df[\"reviewcopy\"] = df[\"reviewcopy\"].str.lower()\n",
    "\n",
    "'''Removing Punctuations'''\n",
    "PUNCT_TO_REMOVE = string.punctuation\n",
    "def remove_punctuation(text):\n",
    "    \"\"\"custom function to remove the punctuation\"\"\"\n",
    "    return text.translate(str.maketrans('', '', PUNCT_TO_REMOVE))\n",
    "\n",
    "df[\"reviewcopy\"] = df[\"reviewcopy\"].apply(lambda text: remove_punctuation(text))\n",
    "\n",
    "\n",
    "'''Removing stopwords'''\n",
    "STOPWORDS = set(stopwords.words('english'))\n",
    "def remove_stopwords(text):\n",
    "    \"\"\"custom function to remove the stopwords\"\"\"\n",
    "    return \" \".join([word for word in str(text).split() if word not in STOPWORDS])\n",
    "\n",
    "df[\"reviewcopy\"] = df[\"reviewcopy\"].apply(lambda text: remove_stopwords(text))\n",
    "\n",
    "\n",
    "'''Removal of URL'''\n",
    "def remove_urls(text):\n",
    "    url_pattern = re.compile(r'https?://\\S+|www\\.\\S+')\n",
    "    return url_pattern.sub(r'', text)\n",
    "df[\"reviewcopy\"] = df[\"reviewcopy\"].apply(lambda text: remove_urls(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#19 lexical Density\n",
    "df['#ofwordswostp'] = df['reviewcopy'].str.count(' ') + 1\n",
    "df['le_d'] = (df['#ofwordswostp']/df['#ofwords'])*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('fullwaydone.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'date', 'user_id', 'prod_id', 'rating', 'review', 'label',\n",
       "       'avg_Urating', 'avg_Prating', 'UCcounts', 'PCcounts', '#ofwords',\n",
       "       'Uavg#word', 'ratdev', 'postags', 'nouns', 'noun_count', 'verbs',\n",
       "       'verb_count', 'adverbs', 'adverb_count', 'adjectives', 'adj_count',\n",
       "       'noun%', 'imag_to_info', 'pronouns', 'pronoun_count', 'posspronouns',\n",
       "       'posspronoun_count', 'perprocount', 'selfreference_div', 'tokens',\n",
       "       'capitals', 'text_lemmatized', 'lemmatizedtokens', 'assum_fut_count',\n",
       "       'ones', 'U_rev_perday', 'mul_rev', '4ormore', '2orless',\n",
       "       'pos_to_neg_ratio', 'subjectivity', 'polarity', 'reviewcopy',\n",
       "       '#ofwordswostp', 'le_d'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping unnecessary columns\n",
    "df.drop(['Unnamed: 0','date','user_id','prod_id','review','postags','nouns','noun_count','verbs','verb_count','adverbs', 'adverb_count', 'adjectives', 'adj_count','pronouns', 'pronoun_count', 'posspronouns',\n",
    "       'posspronoun_count', 'perprocount','tokens','text_lemmatized', 'lemmatizedtokens','ones','reviewcopy',\n",
    "       '#ofwordswostp'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['rating', 'label', 'avg_Urating', 'avg_Prating', 'UCcounts', 'PCcounts',\n",
       "       '#ofwords', 'Uavg#word', 'ratdev', 'noun%', 'imag_to_info',\n",
       "       'selfreference_div', 'capitals', 'assum_fut_count', 'U_rev_perday',\n",
       "       'mul_rev', '4ormore', '2orless', 'pos_to_neg_ratio', 'subjectivity',\n",
       "       'polarity', 'le_d'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
